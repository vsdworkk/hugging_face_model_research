# Multi-Model Configuration for WFA Profile Analyzer
# Supports up to 3 models with enable/disable flags

models:
  - name: "llama_3b_Instruct"
    enabled: false
    model_id: "meta-llama/Llama-3.2-3B-Instruct"
    torch_dtype: "auto"
    device_map: "auto"
    is_instruct: true
  
  - name: "llama_1b_Instruct"
    enabled: true
    model_id: "meta-llama/Llama-3.2-1B-Instruct"
    torch_dtype: "auto"
    device_map: "auto"
    is_instruct: true
  
  - name: "gemma-3-1b-it"
    enabled: true
    model_id: "google/gemma-3-1b-it"
    torch_dtype: "auto"
    device_map: "auto"
    is_instruct: true

# IMPORTANT: Do NOT put secrets here.
# Provide HF token via Databricks secret or the 'hf_token' widget (sets HF_TOKEN env).
#hf_token:

generation:
  batch_size: 10
  max_input_tokens: 2000
  max_new_tokens: 2000
  do_sample: false
  num_beams: 1
  handle_long_generation: "hole"  # accepted but ignored by pipeline call

data:
  dataset_column: "about_me"
  output_column: "about_me_processed"
  human_label_column: "Human_flag"

evaluation:
  save_wide_table: true
  positive_class: "bad"
