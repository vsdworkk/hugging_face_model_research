# Multi-Model Configuration for WFA Profile Analyzer
# Supports up to 3 models with enable/disable flags

models:
  - name: "llama_3b"
    enabled: true
    model_id: "meta-llama/Llama-3.2-3B-Instruct"
    torch_dtype: "auto"
    device_map: "auto"

  - name: "llama_8b"
    enabled: true
    model_id: "meta-llama/Llama-3-8B-Instruct"
    torch_dtype: "auto"
    device_map: "auto"

  - name: "mistral_7b"
    enabled: true
    model_id: "mistralai/Mistral-7B-Instruct-v0.2"
    torch_dtype: "auto"
    device_map: "auto"

# IMPORTANT: Do NOT put secrets here.
# Provide HF token via Databricks secret or the 'hf_token' widget (sets HF_TOKEN env).
hf_token:

generation:
  batch_size: 10
  max_input_tokens: 2000
  max_new_tokens: 2000
  do_sample: false
  num_beams: 1
  handle_long_generation: "hole"  # accepted but ignored by pipeline call

data:
  dataset_column: "about_me"
  output_column: "about_me_processed"
  human_label_column: "Human_flag"

evaluation:
  save_wide_table: true
  positive_class: "bad"
