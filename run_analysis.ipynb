{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a21d6a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "# Install requirements (uncomment if needed)\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "import pandas as pd\n",
    "from src.analyzer import analyze_profiles, load_config\n",
    "from src.evaluate import evaluate_all_models\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Load configuration\n",
    "config = load_config('config.yaml')\n",
    "\n",
    "# Get paths from config\n",
    "INPUT_PATH = config['paths']['input_data']\n",
    "RESULTS_OUTPUT_PATH = config['paths']['results_output']\n",
    "METRICS_OUTPUT_PATH = config['paths']['metrics_output']\n",
    "\n",
    "# Show enabled models\n",
    "enabled_models = [m for m in config['models'] if m.get('enabled', True)]\n",
    "print(f\"Enabled models: {len(enabled_models)}\")\n",
    "for m in enabled_models:\n",
    "    print(f\"  - {m['name']}: {m['model_id']}\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(INPUT_PATH)\n",
    "print(f\"Loaded {len(df)} profiles\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f075da7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Run analysis and evaluate models\n",
    "\n",
    "# Run analysis\n",
    "results = analyze_profiles(\n",
    "    df,\n",
    "    config,\n",
    "    input_col=config.get('input_column', 'about_me'),\n",
    "    batch_size=config.get('batch_size', 10),\n",
    "    max_new_tokens=config.get('max_new_tokens', 2000)\n",
    ")\n",
    "\n",
    "# Evaluate models against human labels\n",
    "\n",
    "model_names = [m['name'] for m in enabled_models]\n",
    "\n",
    "comparison = evaluate_all_models(\n",
    "    results, \n",
    "    model_names,\n",
    "    true_col=config['human_label_column'],\n",
    "    print_individual_reports=False  # Set to True if you want detailed reports\n",
    ")\n",
    "\n",
    "# Save metrics and results with Spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"ProfileAnalyzer\").getOrCreate()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "\n",
    "# Convert pandas to Spark DataFrames and save\n",
    "metrics_filename = METRICS_OUTPUT_PATH.format(timestamp=timestamp).replace('.csv', '')\n",
    "spark_comparison = spark.createDataFrame(comparison)\n",
    "spark_comparison.coalesce(1).write.mode('overwrite').option('header', 'true').csv(metrics_filename)\n",
    "print(f\"\\nModel metrics saved to: {metrics_filename}\")\n",
    "\n",
    "results_filename = RESULTS_OUTPUT_PATH.format(timestamp=timestamp).replace('.csv', '')\n",
    "spark_results = spark.createDataFrame(results)\n",
    "spark_results.coalesce(1).write.mode('overwrite').option('header', 'true').csv(results_filename)\n",
    "print(f\"Results saved to {results_filename}\")\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
