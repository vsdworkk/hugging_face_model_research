{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a21d6a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "# Setup\n",
    "# Install required packages\n",
    "%pip install -r \"requirements.txt\" --extra-index-url https://download.pytorch.org/whl/cu128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98614e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "import pandas as pd\n",
    "from src.analyzer import analyze_profiles, load_config\n",
    "from src.evaluate import evaluate_all_models\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import shutil as shutil\n",
    "import os as os\n",
    "\n",
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Load configuration\n",
    "config = load_config('config.yaml')\n",
    "\n",
    "# Get paths from config\n",
    "INPUT_PATH = config['paths']['input_data']\n",
    "RESULTS_OUTPUT_PATH = config['paths']['results_output']\n",
    "METRICS_OUTPUT_PATH = config['paths']['metrics_output']\n",
    "\n",
    "# Show enabled models\n",
    "enabled_models = [m for m in config['models'] if m.get('enabled', True)]\n",
    "print(f\"Enabled models: {len(enabled_models)}\")\n",
    "for m in enabled_models:\n",
    "    print(f\"  - {m['name']}: {m['model_id']}\")\n",
    "\n",
    "# Print model args for pipeline\n",
    "\n",
    "# Print model args for pipeline (added)\n",
    "from src.analyzer import build_pipeline_args, debug_print_pipeline_args\n",
    "\n",
    "hf_token = (\n",
    "    os.getenv(\"HF_TOKEN\")\n",
    ")\n",
    "print(f\"HF token present?\", bool(hf_token))\n",
    "\n",
    "for m in enabled_models:\n",
    "    args = build_pipeline_args(m, hf_token)\n",
    "    debug_print_pipeline_args(args)\n",
    "    \n",
    "# Load data\n",
    "df = spark.read.csv(INPUT_PATH, header=True, inferSchema=True)\n",
    "df = df.toPandas()\n",
    "\n",
    "print(f\"Loaded {len(df)} profiles\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Run analysis\n",
    "results = analyze_profiles(\n",
    "    df,\n",
    "    config,\n",
    "    input_col=config.get('input_column', 'about_me'),\n",
    "    batch_size=config.get('batch_size', 10),\n",
    "    max_new_tokens=config.get('max_new_tokens', 2000)\n",
    ")\n",
    "\n",
    "# Evaluate models against human labels\n",
    "model_names = [m['name'] for m in enabled_models]\n",
    "comparison = evaluate_all_models(\n",
    "    results,\n",
    "    model_names,\n",
    "    true_col=config['human_label_column'],\n",
    ")\n",
    "\n",
    "# Save metrics and results\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "\n",
    "# Convert pandas to Spark DataFrames and save\n",
    "metrics_filename = METRICS_OUTPUT_PATH.format(timestamp=timestamp).replace('.csv', '')\n",
    "spark_comparison = spark.createDataFrame(comparison)\n",
    "spark_comparison.coalesce(1).write.mode('overwrite').option('header', 'true').csv(metrics_filename)\n",
    "print(f\"Model metrics saved to: {metrics_filename}\")\n",
    "\n",
    "# Convert array columns to strings for Spark CSV compatibility\n",
    "results_for_spark = results.copy()\n",
    "for col in results_for_spark.columns:\n",
    "    if col.endswith('_tags') or col.endswith('_improvement_points'):\n",
    "        results_for_spark[col] = results_for_spark[col].astype(str)\n",
    "\n",
    "results_filename = RESULTS_OUTPUT_PATH.format(timestamp=timestamp).replace('.csv', '')\n",
    "spark_results = spark.createDataFrame(results_for_spark)\n",
    "spark_results.coalesce(1).write.mode('overwrite').option('header', 'true').csv(results_filename)\n",
    "print(f\"Results saved to {results_filename}\")\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f075da7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Cell 2 Version that works.\n",
    "\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import torch\n",
    "\n",
    "# Hub flags (optional, matches your working snippet)\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\"\n",
    "os.environ[\"HF_HUB_DISABLE_XET\"] = \"1\"\n",
    "\n",
    "# Load .env robustly\n",
    "dotenv_path = find_dotenv(usecwd=True)\n",
    "print(f\"Using .env at:\", dotenv_path if dotenv_path else \"(not found)\")\n",
    "load_dotenv(dotenv_path, override=True)\n",
    "\n",
    "# Import analyzer helpers\n",
    "from src.analyzer import build_pipeline_args, debug_print_pipeline_args, load_model_pipeline\n",
    "\n",
    "# Minimal model_config (same as your working snippet)\n",
    "model_config = {\n",
    "    \"name\": \"Llama3-8b\",\n",
    "    \"model_id\": \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    \"is_instruct\": True,\n",
    "    \"device_map\": \"auto\",\n",
    "    \"torch_dtype\": \"auto\", # or \"bfloat16\"/\"float16\"/\"float32\"\n",
    "}\n",
    "\n",
    "# Resolve token\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "# Build and print the exact args we will send to transformers.pipeline\n",
    "args = build_pipeline_args(model_config, hf_token)\n",
    "debug_print_pipeline_args(args)\n",
    "\n",
    "# Load pipeline (uses exactly those args)\n",
    "pipe = load_model_pipeline(model_config, hf_token)\n",
    "print(f\"Pipeline created:\", type(pipe).__name__, \"| Model:\", pipe.model.__class__.__name__)\n",
    "\n",
    "# Tiny generation to confirm E2E\n",
    "messages = [{\"role\": \"user\", \"content\": \"Say hello in one short sentence.\"}]\n",
    "out = pipe(messages, max_new_tokens=16, temperature=0.7)\n",
    "print(\"OK ->\", out[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16c0346",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Run this once - copies from your workspace to persistent DBFS\n",
    "dbutils.fs.mkdirs(\"dbfs:/FileStore/harmony_encodings\")\n",
    "\n",
    "# Adjust the workspace path to where you uploaded the files\n",
    "workspace_path = \"/Workspace/Repos/vthedataeng@gmail.com/wfa_profile_analyzer\"\n",
    "\n",
    "dbutils.fs.cp(f\"file:{workspace_path}/o200k_base.tiktoken\", \"dbfs:/FileStore/harmony_encodings/o200k_base.tiktoken\")\n",
    "dbutils.fs.cp(f\"file:{workspace_path}/cl100k_base.tiktoken\", \"dbfs:/FileStore/harmony_encodings/cl100k_base.tiktoken\")\n",
    "\n",
    "# Verify\n",
    "display(dbutils.fs.ls(\"dbfs:/FileStore/harmony_encodings\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
